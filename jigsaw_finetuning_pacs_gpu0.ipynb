{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cartoon-photo-sketch to art_painting - 31 jigsaw classes, split 0\n",
      "Using Caffe AlexNet\n",
      "Dataset size: train 7150, val 793, test 2048\n",
      "Step size: 24\n",
      "Saving to /home/enoon/code/2018/JigsawDA/myJigsaw/utils/../logs/tmp/cartoon-photo-sketch_to_art_painting/eps30_bs128_lr0.001_class7_jigClass31_jigWeight0.5_TAll_bias0.6_classifyOnlySane__0flipP_nest_916\n",
      "New epoch - lr: 0.001\n",
      "0/55 of epoch 1/30 jigsaw : 3.461, class : 1.986 - acc jigsaw : 3.91, class : 12.50 [bs:128]\n",
      "30/55 of epoch 1/30 jigsaw : 1.412, class : 0.593 - acc jigsaw : 63.28, class : 64.84 [bs:128]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/enoon/code/2018/JigsawDA/myJigsaw/data/concat_dataset.py\", line 48, in __getitem__\n    return self.datasets[dataset_idx][sample_idx], dataset_idx\n  File \"/home/enoon/code/2018/JigsawDA/myJigsaw/data/JigsawLoader.py\", line 119, in __getitem__\n    return self._image_transformer(img), 0, int(self.labels[index])\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n    return img.resize((ow, oh), interpolation)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1724, in resize\n    raise ValueError(\"unknown resampling filter\")\nValueError: unknown resampling filter\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-269b5e03562f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                                                                       i))\n\u001b[1;32m     71\u001b[0m                     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/2018/JigsawDA/myJigsaw/train_jigsaw.py\u001b[0m in \u001b[0;36mdo_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mval_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/2018/JigsawDA/myJigsaw/train_jigsaw.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Single vs multi: %g %g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_correct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                     \u001b[0mjigsaw_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mjigsaw_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjigsaw_correct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mclass_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_correct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/2018/JigsawDA/myJigsaw/train_jigsaw.py\u001b[0m in \u001b[0;36mdo_test\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mclass_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdomain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjig_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjig_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjig_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mjigsaw_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/enoon/code/2018/JigsawDA/myJigsaw/data/concat_dataset.py\", line 48, in __getitem__\n    return self.datasets[dataset_idx][sample_idx], dataset_idx\n  File \"/home/enoon/code/2018/JigsawDA/myJigsaw/data/JigsawLoader.py\", line 119, in __getitem__\n    return self._image_transformer(img), 0, int(self.labels[index])\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n    return img.resize((ow, oh), interpolation)\n  File \"/home/enoon/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1724, in resize\n    raise ValueError(\"unknown resampling filter\")\nValueError: unknown resampling filter\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from data import data_helper\n",
    "from data.data_helper import available_datasets\n",
    "from models import model_factory\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from utils.Logger import Logger\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from train_jigsaw import Trainer\n",
    "from utils import vis\n",
    "\n",
    "class Container():\n",
    "    pass\n",
    "\n",
    "args = Container()\n",
    "args.batch_size = 128\n",
    "args.n_classes = 7\n",
    "args.learning_rate = 0.001\n",
    "args.epochs = 30\n",
    "args.network = \"caffenet\"\n",
    "args.val_size = 0.1\n",
    "args.tf_logger = True\n",
    "args.folder_name = \"tmp\" # odd_one_out\n",
    "args.jigsaw_n_classes = 31\n",
    "\n",
    "args.train_all = True\n",
    "# args.jig_weight = 0.9\n",
    "# args.bias_whole_image = 0.8\n",
    "args.TTA = False\n",
    "args.suffix = \"nesterov\"\n",
    "args.image_size = 225\n",
    "args.nesterov = True\n",
    "\n",
    "args.limit_source = None\n",
    "args.limit_target = None\n",
    "args.min_scale = 0.8\n",
    "args.max_scale = 1.0\n",
    "args.random_horiz_flip = 0\n",
    "args.jitter = 0\n",
    "args.tile_random_grayscale = 0.1\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "args.classify_only_sane = True\n",
    "\n",
    "for args.nesterov in [True, False]:\n",
    "    for args.jig_weight in [0.5, 0.7, 0.9]: \n",
    "        for args.bias_whole_image in [0.6, 0.8, 0.9]:\n",
    "            for k, x in enumerate(source):\n",
    "                args.source = source[:k]+source[k+1:]\n",
    "                args.target = x\n",
    "                args.suffix = \"_%gflipP\" % (args.random_horiz_flip)\n",
    "                if args.nesterov:\n",
    "                    args.suffix += \"_nest\"\n",
    "                for i in range(3):\n",
    "                    print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                                      args.target, \n",
    "                                                                      args.jigsaw_n_classes,\n",
    "                                                                      i))\n",
    "                    trainer = Trainer(args, device)\n",
    "                    trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "args.epochs = 30\n",
    "args.jigsaw_n_classes = 31\n",
    "for args.bias_whole_image in [None, 0.1, 0.3, 0.5]:\n",
    "    for args.classify_only_sane in [True, False]:\n",
    "        print(\"===============================\\n\")\n",
    "        for k, x in enumerate(source):\n",
    "            args.source = source[:k]+source[k+1:]\n",
    "            args.target = x\n",
    "            for i in range(3):\n",
    "                print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                                  args.target, \n",
    "                                                                  args.jigsaw_n_classes,\n",
    "                                                                  i))\n",
    "                trainer = Trainer(args, device)\n",
    "                trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "for args.jigsaw_n_classes in [1,3,5,10,20]:\n",
    "    args.epochs = int((80/95)*args.jigsaw_n_classes+15)\n",
    "    for k, x in enumerate(source):\n",
    "        args.source = source[:k]+source[k+1:]\n",
    "        args.target = x\n",
    "        for i in range(3):\n",
    "            print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                              args.target, \n",
    "                                                              args.jigsaw_n_classes,\n",
    "                                                              i))\n",
    "            trainer = Trainer(args, device)\n",
    "            trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (\"-\".join(args.source),\n",
    "                                                            args.target,args.epochs, args.jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.title(\"%s->%s eps:%d jigweight:%.2f\" % (str(source),target,epochs, jig_weight))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "conv1 = models.alexnet(pretrained=True).features[0] #model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv1 = model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(memory[\"train\"], label=\"train\")\n",
    "plt.plot(memory[\"val\"], label=\"val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# iter_c = iter(train_datasets)\n",
    "\n",
    "# for x in range(5):\n",
    "#     tmp = next(iter_c)\n",
    "#     image = to_plt(tmp[0])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.data_helper import get_val_dataloader, get_train_dataloader\n",
    "from os.path import join, dirname\n",
    "# from data.JigsawLoader import JigsawTestDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "loader = get_val_dataloader(\"photo\",31,batch_size=10,multi=False)\n",
    "# loader, _ = get_train_dataloader([\"photo\"],31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    return inp\n",
    "\n",
    "# dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)\n",
    "# test = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "iter_c = iter(loader)\n",
    "(tmp, v, c), d = next(iter_c)\n",
    "\n",
    "for x in range(tmp.shape[0]):\n",
    "#     image = tmp[0, x]\n",
    "    image = torchvision.utils.make_grid(tmp[x],1,normalize=True)\n",
    "    plt.imshow(to_plt(image))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# print(v.max(), v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.max(), tmp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.JigsawLoader import JigsawDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._augment_tile = transforms.Compose([\n",
    "#             transforms.RandomCrop(64),\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        data = torch.stack(tiles, 0)\n",
    "        return self.returnFunc(data), 0, int(self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([np.random.randint(9) for x in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.load(\"permutations_31.npy\")\n",
    "perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stuff():\n",
    "    print(\"done\")\n",
    "\n",
    "a = {\"ciao\":0}\n",
    "try:\n",
    "    a[\"cigao\"]\n",
    "except KeyError:\n",
    "    stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))\n",
    "a[:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
