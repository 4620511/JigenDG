{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data import data_helper\n",
    "from data.data_helper import available_datasets\n",
    "from models import model_factory\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from utils.Logger import Logger\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from train_jigsaw import do_training\n",
    "from utils import vis\n",
    "\n",
    "class Container():\n",
    "    pass\n",
    "\n",
    "args = Container()\n",
    "args.batch_size = 128\n",
    "args.jigsaw_n_classes = 31\n",
    "args.n_classes = 7\n",
    "args.learning_rate = 0.001\n",
    "args.epochs = 30\n",
    "args.source = [\"art_painting\", \"photo\", \"cartoon\"]\n",
    "args.target = \"sketch\" # source[target_id]\n",
    "args.network = \"caffenet\"\n",
    "args.jig_weight = 0.2\n",
    "args.val_size = 0.1\n",
    "args.tf_logger = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Caffe AlexNet\n",
      "AlexNetCaffe(\n",
      "  (features): Sequential(\n",
      "    (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (relu1): ReLU(inplace)\n",
      "    (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace)\n",
      "    (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (relu4): ReLU(inplace)\n",
      "    (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (relu5): ReLU(inplace)\n",
      "    (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (fc6): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (relu6): ReLU(inplace)\n",
      "    (drop6): Dropout(p=0.5)\n",
      "    (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (relu7): ReLU(inplace)\n",
      "    (drop7): Dropout(p=0.5)\n",
      "  )\n",
      "  (jigsaw_classifier): Linear(in_features=4096, out_features=32, bias=True)\n",
      "  (class_classifier): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")\n",
      "Dataset size: train 5457, val 605, test 3929\n",
      "Step size: 24\n",
      "Saving to /home/enoon/code/2018/JigsawDA/myJigsaw/utils/../logs/art_painting-cartoon-photo_to_sketch/eps30_bs128_lr0.001_class7_jigClass31_jigWeight0.2_787\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 1/30 jigsaw : 3.533574, class : 2.000720 - acc jigsaw : 0.007812, class : 0.148438 [bs:128]\n",
      "10/42 of epoch 1/30 jigsaw : 3.484319, class : 1.212581 - acc jigsaw : 0.023438, class : 0.601562 [bs:128]\n",
      "20/42 of epoch 1/30 jigsaw : 3.503910, class : 1.072066 - acc jigsaw : 0.054688, class : 0.609375 [bs:128]\n",
      "30/42 of epoch 1/30 jigsaw : 3.438071, class : 1.149033 - acc jigsaw : 0.070312, class : 0.570312 [bs:128]\n",
      "40/42 of epoch 1/30 jigsaw : 3.428900, class : 1.017727 - acc jigsaw : 0.046875, class : 0.632812 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.100826, class : 0.786777\n",
      "Accuracies on test: jigsaw : 0.018580, class : 0.423772\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 2/30 jigsaw : 3.472097, class : 0.892291 - acc jigsaw : 0.054688, class : 0.640625 [bs:128]\n",
      "10/42 of epoch 2/30 jigsaw : 3.409261, class : 0.885095 - acc jigsaw : 0.070312, class : 0.656250 [bs:128]\n",
      "20/42 of epoch 2/30 jigsaw : 3.414713, class : 0.913985 - acc jigsaw : 0.039062, class : 0.671875 [bs:128]\n",
      "30/42 of epoch 2/30 jigsaw : 3.354484, class : 0.777587 - acc jigsaw : 0.085938, class : 0.710938 [bs:128]\n",
      "40/42 of epoch 2/30 jigsaw : 3.375301, class : 0.858420 - acc jigsaw : 0.070312, class : 0.726562 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.557025, class : 0.829752\n",
      "Accuracies on test: jigsaw : 0.689997, class : 0.451005\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 3/30 jigsaw : 3.360294, class : 0.842804 - acc jigsaw : 0.093750, class : 0.679688 [bs:128]\n",
      "10/42 of epoch 3/30 jigsaw : 3.336954, class : 0.793034 - acc jigsaw : 0.125000, class : 0.742188 [bs:128]\n",
      "20/42 of epoch 3/30 jigsaw : 3.368282, class : 0.760709 - acc jigsaw : 0.046875, class : 0.750000 [bs:128]\n",
      "30/42 of epoch 3/30 jigsaw : 3.272456, class : 0.802332 - acc jigsaw : 0.164062, class : 0.679688 [bs:128]\n",
      "40/42 of epoch 3/30 jigsaw : 3.323444, class : 0.835169 - acc jigsaw : 0.062500, class : 0.664062 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.685950, class : 0.831405\n",
      "Accuracies on test: jigsaw : 0.684144, class : 0.411810\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 4/30 jigsaw : 3.314336, class : 0.784098 - acc jigsaw : 0.125000, class : 0.742188 [bs:128]\n",
      "10/42 of epoch 4/30 jigsaw : 3.232851, class : 0.774201 - acc jigsaw : 0.085938, class : 0.679688 [bs:128]\n",
      "20/42 of epoch 4/30 jigsaw : 3.269969, class : 0.805306 - acc jigsaw : 0.070312, class : 0.742188 [bs:128]\n",
      "30/42 of epoch 4/30 jigsaw : 3.239839, class : 0.955261 - acc jigsaw : 0.140625, class : 0.687500 [bs:128]\n",
      "40/42 of epoch 4/30 jigsaw : 3.272836, class : 0.825747 - acc jigsaw : 0.078125, class : 0.687500 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.737190, class : 0.826446\n",
      "Accuracies on test: jigsaw : 0.822856, class : 0.439807\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 5/30 jigsaw : 3.225159, class : 0.837005 - acc jigsaw : 0.148438, class : 0.734375 [bs:128]\n",
      "10/42 of epoch 5/30 jigsaw : 3.224548, class : 1.037319 - acc jigsaw : 0.109375, class : 0.601562 [bs:128]\n",
      "20/42 of epoch 5/30 jigsaw : 3.193491, class : 0.791108 - acc jigsaw : 0.101562, class : 0.718750 [bs:128]\n",
      "30/42 of epoch 5/30 jigsaw : 3.171086, class : 0.639231 - acc jigsaw : 0.179688, class : 0.750000 [bs:128]\n",
      "40/42 of epoch 5/30 jigsaw : 3.183013, class : 0.680918 - acc jigsaw : 0.148438, class : 0.750000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.745455, class : 0.839669\n",
      "Accuracies on test: jigsaw : 0.802240, class : 0.453041\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 6/30 jigsaw : 3.201286, class : 0.674934 - acc jigsaw : 0.148438, class : 0.726562 [bs:128]\n",
      "10/42 of epoch 6/30 jigsaw : 3.228308, class : 0.812619 - acc jigsaw : 0.132812, class : 0.664062 [bs:128]\n",
      "20/42 of epoch 6/30 jigsaw : 3.185237, class : 0.662657 - acc jigsaw : 0.187500, class : 0.734375 [bs:128]\n",
      "30/42 of epoch 6/30 jigsaw : 3.082072, class : 0.741345 - acc jigsaw : 0.148438, class : 0.734375 [bs:128]\n",
      "40/42 of epoch 6/30 jigsaw : 3.198622, class : 0.726721 - acc jigsaw : 0.148438, class : 0.718750 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.748760, class : 0.844628\n",
      "Accuracies on test: jigsaw : 0.828455, class : 0.431917\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 7/30 jigsaw : 3.142982, class : 0.781642 - acc jigsaw : 0.171875, class : 0.703125 [bs:128]\n",
      "10/42 of epoch 7/30 jigsaw : 3.171370, class : 0.815926 - acc jigsaw : 0.156250, class : 0.710938 [bs:128]\n",
      "20/42 of epoch 7/30 jigsaw : 3.130283, class : 0.776306 - acc jigsaw : 0.156250, class : 0.718750 [bs:128]\n",
      "30/42 of epoch 7/30 jigsaw : 3.051360, class : 0.581060 - acc jigsaw : 0.179688, class : 0.828125 [bs:128]\n",
      "40/42 of epoch 7/30 jigsaw : 3.122414, class : 0.796613 - acc jigsaw : 0.140625, class : 0.695312 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.800000, class : 0.852893\n",
      "Accuracies on test: jigsaw : 0.816747, class : 0.444133\n",
      "New epoch - lr: 0.0, 0.001\n"
     ]
    }
   ],
   "source": [
    "from train_jigsaw import Trainer\n",
    "\n",
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (\"-\".join(args.source),\n",
    "                                                            args.target,args.epochs, args.jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.title(\"%s->%s eps:%d jigweight:%.2f\" % (str(source),target,epochs, jig_weight))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "conv1 = models.alexnet(pretrained=True).features[0] #model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv1 = model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(memory[\"train\"], label=\"train\")\n",
    "plt.plot(memory[\"val\"], label=\"val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# iter_c = iter(train_datasets)\n",
    "\n",
    "# for x in range(5):\n",
    "#     tmp = next(iter_c)\n",
    "#     image = to_plt(tmp[0])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os.path import join, dirname\n",
    "# from data.JigsawLoader import JigsawTestDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)\n",
    "# test = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "iter_c = iter(data_helper.get_dataloader(\"photo\", 31, \"train\"))\n",
    "(tmp, v, c), d = next(iter_c)\n",
    "for x in range(10):\n",
    "    image = tmp[x]\n",
    "    image = torchvision.utils.make_grid(tmp[x],1,normalize=True)\n",
    "    plt.imshow(to_plt(image))\n",
    "    plt.show()\n",
    "    print(v[x],c[x])\n",
    "    \n",
    "print(v.max(), v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d[d==k].shape for k in [0,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.JigsawLoader import JigsawDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._augment_tile = transforms.Compose([\n",
    "#             transforms.RandomCrop(64),\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        data = torch.stack(tiles, 0)\n",
    "        return self.returnFunc(data), 0, int(self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.load(\"permutations_31.npy\")\n",
    "perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
