{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cartoon-photo-sketch to art_painting - 31 jigsaw classes, split 0\n",
      "Using Caffe AlexNet\n",
      "Dataset size: train 7150, val 793, test 2048\n",
      "Step size: 24\n",
      "Saving to /home/enoon/code/2018/JigsawDA/myJigsaw/utils/../logs/test/cartoon-photo-sketch_to_art_painting/eps30_bs128_lr0.001_class7_jigClass31_jigWeight0.9_bias0.8_classifyOnlySane_TTA_855\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 1/30 jigsaw : 3.456380, class : 1.990755 - acc jigsaw : 0.046875, class : 0.140625 [bs:128]\n",
      "30/55 of epoch 1/30 jigsaw : 0.779950, class : 0.765542 - acc jigsaw : 0.812500, class : 0.703125 [bs:128]\n",
      "Accuracies on val: jigsaw : 1.000000, class : 0.844893\n",
      "Single vs multi: 0.605469 0.592773\n",
      "Accuracies on test: jigsaw : 1.000000, class : 0.592773\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 2/30 jigsaw : 0.770560, class : 0.392745 - acc jigsaw : 0.804688, class : 0.765625 [bs:128]\n",
      "30/55 of epoch 2/30 jigsaw : 0.971272, class : 0.550318 - acc jigsaw : 0.773438, class : 0.726562 [bs:128]\n",
      "Accuracies on val: jigsaw : 1.000000, class : 0.861286\n",
      "Single vs multi: 0.641602 0.624023\n",
      "Accuracies on test: jigsaw : 0.998535, class : 0.624023\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 3/30 jigsaw : 0.711716, class : 0.316642 - acc jigsaw : 0.820312, class : 0.859375 [bs:128]\n",
      "30/55 of epoch 3/30 jigsaw : 0.735755, class : 0.337845 - acc jigsaw : 0.820312, class : 0.835938 [bs:128]\n",
      "Accuracies on val: jigsaw : 1.000000, class : 0.881463\n",
      "Single vs multi: 0.634766 0.62207\n",
      "Accuracies on test: jigsaw : 0.997559, class : 0.622070\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 4/30 jigsaw : 0.745261, class : 0.307300 - acc jigsaw : 0.820312, class : 0.835938 [bs:128]\n",
      "30/55 of epoch 4/30 jigsaw : 0.636130, class : 0.275011 - acc jigsaw : 0.835938, class : 0.843750 [bs:128]\n",
      "Accuracies on val: jigsaw : 1.000000, class : 0.866330\n",
      "Single vs multi: 0.647461 0.633789\n",
      "Accuracies on test: jigsaw : 0.996582, class : 0.633789\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 5/30 jigsaw : 0.906414, class : 0.186048 - acc jigsaw : 0.757812, class : 0.843750 [bs:128]\n",
      "30/55 of epoch 5/30 jigsaw : 0.776816, class : 0.337061 - acc jigsaw : 0.820312, class : 0.812500 [bs:128]\n",
      "Accuracies on val: jigsaw : 1.000000, class : 0.891551\n",
      "Single vs multi: 0.644531 0.625488\n",
      "Accuracies on test: jigsaw : 0.997070, class : 0.625488\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 6/30 jigsaw : 0.571208, class : 0.204737 - acc jigsaw : 0.828125, class : 0.828125 [bs:128]\n",
      "30/55 of epoch 6/30 jigsaw : 0.760693, class : 0.228385 - acc jigsaw : 0.812500, class : 0.812500 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.889029\n",
      "Single vs multi: 0.637695 0.624023\n",
      "Accuracies on test: jigsaw : 0.996094, class : 0.624023\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 7/30 jigsaw : 0.557919, class : 0.177359 - acc jigsaw : 0.828125, class : 0.921875 [bs:128]\n",
      "30/55 of epoch 7/30 jigsaw : 0.368701, class : 0.208292 - acc jigsaw : 0.906250, class : 0.890625 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.899117\n",
      "Single vs multi: 0.633789 0.623535\n",
      "Accuracies on test: jigsaw : 0.995605, class : 0.623535\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 8/30 jigsaw : 0.551695, class : 0.217288 - acc jigsaw : 0.843750, class : 0.835938 [bs:128]\n",
      "30/55 of epoch 8/30 jigsaw : 0.564869, class : 0.257523 - acc jigsaw : 0.843750, class : 0.820312 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.892812\n",
      "Single vs multi: 0.654297 0.647949\n",
      "Accuracies on test: jigsaw : 0.995117, class : 0.647949\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 9/30 jigsaw : 0.623967, class : 0.153074 - acc jigsaw : 0.835938, class : 0.851562 [bs:128]\n",
      "30/55 of epoch 9/30 jigsaw : 0.500125, class : 0.223911 - acc jigsaw : 0.835938, class : 0.867188 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.906683\n",
      "Single vs multi: 0.652832 0.650391\n",
      "Accuracies on test: jigsaw : 0.993652, class : 0.650391\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 10/30 jigsaw : 0.557895, class : 0.131902 - acc jigsaw : 0.843750, class : 0.875000 [bs:128]\n",
      "30/55 of epoch 10/30 jigsaw : 0.430005, class : 0.122082 - acc jigsaw : 0.882812, class : 0.921875 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.996217, class : 0.905422\n",
      "Single vs multi: 0.65332 0.652344\n",
      "Accuracies on test: jigsaw : 0.994141, class : 0.652344\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 11/30 jigsaw : 0.311623, class : 0.152905 - acc jigsaw : 0.906250, class : 0.867188 [bs:128]\n",
      "30/55 of epoch 11/30 jigsaw : 0.374140, class : 0.141497 - acc jigsaw : 0.898438, class : 0.882812 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.894073\n",
      "Single vs multi: 0.649414 0.637695\n",
      "Accuracies on test: jigsaw : 0.995605, class : 0.637695\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 12/30 jigsaw : 0.512410, class : 0.191568 - acc jigsaw : 0.882812, class : 0.843750 [bs:128]\n",
      "30/55 of epoch 12/30 jigsaw : 0.451024, class : 0.156265 - acc jigsaw : 0.906250, class : 0.875000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.996217, class : 0.899117\n",
      "Single vs multi: 0.638672 0.632812\n",
      "Accuracies on test: jigsaw : 0.992188, class : 0.632812\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 13/30 jigsaw : 0.448436, class : 0.139344 - acc jigsaw : 0.890625, class : 0.828125 [bs:128]\n",
      "30/55 of epoch 13/30 jigsaw : 0.357877, class : 0.126961 - acc jigsaw : 0.882812, class : 0.875000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.909206\n",
      "Single vs multi: 0.652832 0.639648\n",
      "Accuracies on test: jigsaw : 0.994141, class : 0.639648\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 14/30 jigsaw : 0.591459, class : 0.081249 - acc jigsaw : 0.867188, class : 0.882812 [bs:128]\n",
      "30/55 of epoch 14/30 jigsaw : 0.768423, class : 0.130700 - acc jigsaw : 0.773438, class : 0.773438 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.912989\n",
      "Single vs multi: 0.651855 0.651367\n",
      "Accuracies on test: jigsaw : 0.995605, class : 0.651367\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 15/30 jigsaw : 0.536704, class : 0.066314 - acc jigsaw : 0.851562, class : 0.921875 [bs:128]\n",
      "30/55 of epoch 15/30 jigsaw : 0.331587, class : 0.090322 - acc jigsaw : 0.890625, class : 0.867188 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.909206\n",
      "Single vs multi: 0.651855 0.638184\n",
      "Accuracies on test: jigsaw : 0.992676, class : 0.638184\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 16/30 jigsaw : 0.383493, class : 0.066732 - acc jigsaw : 0.890625, class : 0.937500 [bs:128]\n",
      "30/55 of epoch 16/30 jigsaw : 0.554052, class : 0.092984 - acc jigsaw : 0.875000, class : 0.851562 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.998739, class : 0.905422\n",
      "Single vs multi: 0.651367 0.640137\n",
      "Accuracies on test: jigsaw : 0.992188, class : 0.640137\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 17/30 jigsaw : 0.422945, class : 0.075866 - acc jigsaw : 0.898438, class : 0.875000 [bs:128]\n",
      "30/55 of epoch 17/30 jigsaw : 0.395004, class : 0.060509 - acc jigsaw : 0.882812, class : 0.882812 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.904161\n",
      "Single vs multi: 0.646973 0.638672\n",
      "Accuracies on test: jigsaw : 0.992188, class : 0.638672\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 18/30 jigsaw : 0.372498, class : 0.080300 - acc jigsaw : 0.882812, class : 0.875000 [bs:128]\n",
      "30/55 of epoch 18/30 jigsaw : 0.363025, class : 0.101136 - acc jigsaw : 0.890625, class : 0.875000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.994956, class : 0.916772\n",
      "Single vs multi: 0.655762 0.646973\n",
      "Accuracies on test: jigsaw : 0.990234, class : 0.646973\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 19/30 jigsaw : 0.237226, class : 0.113577 - acc jigsaw : 0.906250, class : 0.890625 [bs:128]\n",
      "30/55 of epoch 19/30 jigsaw : 0.496047, class : 0.057481 - acc jigsaw : 0.843750, class : 0.937500 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.916772\n",
      "Single vs multi: 0.649902 0.64502\n",
      "Accuracies on test: jigsaw : 0.992188, class : 0.645020\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 20/30 jigsaw : 0.450258, class : 0.084400 - acc jigsaw : 0.859375, class : 0.843750 [bs:128]\n",
      "30/55 of epoch 20/30 jigsaw : 0.307948, class : 0.081360 - acc jigsaw : 0.921875, class : 0.898438 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.997478, class : 0.911728\n",
      "Single vs multi: 0.650879 0.644531\n",
      "Accuracies on test: jigsaw : 0.993652, class : 0.644531\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/55 of epoch 21/30 jigsaw : 0.257782, class : 0.049217 - acc jigsaw : 0.914062, class : 0.898438 [bs:128]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from data import data_helper\n",
    "from data.data_helper import available_datasets\n",
    "from models import model_factory\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from utils.Logger import Logger\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from train_jigsaw import Trainer\n",
    "from utils import vis\n",
    "\n",
    "class Container():\n",
    "    pass\n",
    "\n",
    "args = Container()\n",
    "args.batch_size = 128\n",
    "args.n_classes = 7\n",
    "args.learning_rate = 0.001\n",
    "args.epochs = 30\n",
    "args.network = \"caffenet\"\n",
    "args.val_size = 0.1\n",
    "args.tf_logger = True\n",
    "args.folder_name = \"test\"\n",
    "args.jigsaw_n_classes = 31\n",
    "args.classify_only_sane = True\n",
    "args.jig_weight = 0.9\n",
    "args.bias_whole_image = 0.8\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "for args.TTA in [True, False]: \n",
    "    for k, x in enumerate(source):\n",
    "        args.source = source[:k]+source[k+1:]\n",
    "        args.target = x\n",
    "        for i in range(3):\n",
    "            print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                              args.target, \n",
    "                                                              args.jigsaw_n_classes,\n",
    "                                                              i))\n",
    "            trainer = Trainer(args, device)\n",
    "            trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "for args.jig_weight in [0.0]:\n",
    "    print(\"\\n======================\\n%g\\n===================\" % args.jig_weight)\n",
    "    for args.bias_whole_image in [1.0]: # [None, 0.01, 0.05, 0.1, 0.3, 0.5]:\n",
    "        for k, x in enumerate(source):\n",
    "            args.source = source[:k]+source[k+1:]\n",
    "            args.target = x\n",
    "            for i in range(3):\n",
    "                print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                                  args.target, \n",
    "                                                                  args.jigsaw_n_classes,\n",
    "                                                                  i))\n",
    "                trainer = Trainer(args, device)\n",
    "                trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (\"-\".join(args.source),\n",
    "                                                            args.target,args.epochs, args.jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\"train\": data_helper.get_dataloader(args.source, args.jigsaw_n_classes, \"train\"),\n",
    "           \"val\": data_helper.get_dataloader(args.target, args.jigsaw_n_classes, \"val\")}\n",
    "dataset_sizes = {\"train\": len(dataloaders[\"train\"].dataset),\n",
    "                \"val\": len(dataloaders[\"val\"].dataset)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim_and_scheduler(network, epochs, lr):\n",
    "    from torch import optim\n",
    "    optimizer = optim.SGD(network.get_params(lr), weight_decay=.0005, momentum=.9, nesterov=True, lr=lr)\n",
    "    step_size = int(epochs * .8)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size)\n",
    "    print(step_size)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "model_ft = model_factory.get_network(\"caffenet\")(jigsaw_classes=args.jigsaw_n_classes+1, classes=args.n_classes)\n",
    "model_ft = model_ft.to(device)\n",
    "# print(model_ft)\n",
    "\n",
    "optimizer, scheduler = get_optim_and_scheduler(model_ft, args.epochs, args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, source, target, optimizer, logger, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for it, ((data, jig_l, class_l), d_idx) in enumerate(source):\n",
    "        data, jig_l, class_l = data.to(device), jig_l.to(device), class_l.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        jigsaw_logit, class_logit = model(data)\n",
    "        jigsaw_loss = criterion(jigsaw_logit, jig_l)\n",
    "        class_loss = criterion(class_logit[d_idx!=target_id], class_l[d_idx!=target_id])\n",
    "        _, cls_pred = class_logit.max(dim=1)\n",
    "        _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "        loss = class_loss + jigsaw_loss * jig_weight\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logger.log(it, len(source), {\"jigsaw\": jigsaw_loss.item(), \"class\": class_loss.item()},\n",
    "                  {\"jigsaw\": torch.sum(jig_pred == jig_l.data).item(), \"class\":torch.sum(cls_pred == class_l.data).item()},\n",
    "                  data.shape[0])\n",
    "        del loss, class_loss, jigsaw_loss, jigsaw_logit, class_logit\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        jigsaw_correct = 0\n",
    "        class_correct = 0\n",
    "        total = 0\n",
    "        for it, ((data, jig_l, class_l), d_idx) in enumerate(target):\n",
    "            data, jig_l, class_l = data.to(device), jig_l.to(device), class_l.to(device)\n",
    "            jigsaw_logit, class_logit = model(data)\n",
    "            _, cls_pred = class_logit.max(dim=1)\n",
    "            _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "            class_correct += torch.sum(cls_pred == class_l.data)\n",
    "            jigsaw_correct += torch.sum(jig_pred == jig_l.data)\n",
    "            total += data.shape[0]\n",
    "        logger.log_test({\"jigsaw\": float(jigsaw_correct) / total,\n",
    "                         \"class\": float(class_correct) / total})\n",
    "\n",
    "\n",
    "def do_training(args, model, source, target, optimizer, scheduler, device):\n",
    "    logger = Logger(args)\n",
    "    for k in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        logger.new_epoch(scheduler.get_lr())\n",
    "        do_epoch(model, source, target, optimizer, logger, device)\n",
    "    return logger, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jig_weight = args.jig_weight\n",
    "logger, model = do_training(args, model_ft, dataloaders[\"train\"], dataloaders[\"val\"], optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (str(args.source),args.target,args.epochs, jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    import numpy as np\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "conv1 = model_ft.features[0] # models.alexnet(pretrained=True).features[0] #model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (str(source),target,epochs, jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,k in enumerate(range(0,l,int(updates))):\n",
    "    print(k, logger.val_acc[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# iter_c = iter(train_datasets)\n",
    "\n",
    "# for x in range(5):\n",
    "#     tmp = next(iter_c)\n",
    "#     image = to_plt(tmp[0])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_helper import get_val_dataloader\n",
    "from os.path import join, dirname\n",
    "# from data.JigsawLoader import JigsawTestDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_val_dataloader(\"photo\",31,batch_size=10,multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    return inp\n",
    "\n",
    "# dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)\n",
    "# test = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "iter_c = iter(loader)\n",
    "(tmp, v, c), d = next(iter_c)\n",
    "print(tmp[:,0].shape)\n",
    "for x in range(tmp.shape[1]):\n",
    "#     image = tmp[0, x]\n",
    "    image = torchvision.utils.make_grid(tmp[0, x],1,normalize=True)\n",
    "    plt.imshow(to_plt(image))\n",
    "    plt.show()\n",
    "    print(v[0,x])\n",
    "\n",
    "    \n",
    "# print(v.max(), v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for k in range(10):\n",
    "    res.append(torch.rand(5, 100))\n",
    "res = torch.stack(res,0)\n",
    "res.mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.JigsawLoader import JigsawDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._augment_tile = transforms.Compose([\n",
    "#             transforms.RandomCrop(64),\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        data = torch.stack(tiles, 0)\n",
    "        return self.returnFunc(data), 0, int(self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = 0\n",
    "for x in range(100):\n",
    "    true += 0.1 > random.random()\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
