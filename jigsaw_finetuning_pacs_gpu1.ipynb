{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data import data_helper\n",
    "from data.data_helper import available_datasets\n",
    "from models import model_factory\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from utils.Logger import Logger\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from train_jigsaw import do_training\n",
    "from utils import vis\n",
    "\n",
    "class Container():\n",
    "    pass\n",
    "\n",
    "args = Container()\n",
    "args.batch_size = 128\n",
    "args.jigsaw_n_classes = 31\n",
    "args.n_classes = 7\n",
    "args.learning_rate = 0.001\n",
    "args.epochs = 30\n",
    "args.source = [\"art_painting\", \"photo\", \"cartoon\"]\n",
    "args.target = \"sketch\" # source[target_id]\n",
    "args.network = \"caffenet\"\n",
    "args.jig_weight = 0.0\n",
    "args.tf_logger = True\n",
    "args.val_size = 0.1\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Caffe AlexNet\n",
      "AlexNetCaffe(\n",
      "  (features): Sequential(\n",
      "    (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (relu1): ReLU(inplace)\n",
      "    (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace)\n",
      "    (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (relu4): ReLU(inplace)\n",
      "    (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (relu5): ReLU(inplace)\n",
      "    (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (fc6): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (relu6): ReLU(inplace)\n",
      "    (drop6): Dropout(p=0.5)\n",
      "    (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (relu7): ReLU(inplace)\n",
      "    (drop7): Dropout(p=0.5)\n",
      "  )\n",
      "  (jigsaw_classifier): Linear(in_features=4096, out_features=32, bias=True)\n",
      "  (class_classifier): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")\n",
      "Dataset size: train 5457, val 605, test 3929\n",
      "Step size: 24\n",
      "Saving to /home/enoon/code/2018/JigsawDA/myJigsaw/utils/../logs/art_painting-cartoon-photo_to_sketch/eps30_bs128_lr0.001_class7_jigClass31_jigWeight0_775\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 1/30 jigsaw : 3.490270, class : 1.962658 - acc jigsaw : 0.039062, class : 0.117188 [bs:128]\n",
      "10/42 of epoch 1/30 jigsaw : 3.454010, class : 1.385480 - acc jigsaw : 0.054688, class : 0.523438 [bs:128]\n",
      "20/42 of epoch 1/30 jigsaw : 3.496587, class : 1.098001 - acc jigsaw : 0.023438, class : 0.609375 [bs:128]\n",
      "30/42 of epoch 1/30 jigsaw : 3.508257, class : 1.026448 - acc jigsaw : 0.015625, class : 0.632812 [bs:128]\n",
      "40/42 of epoch 1/30 jigsaw : 3.509593, class : 0.811020 - acc jigsaw : 0.039062, class : 0.679688 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.014876, class : 0.795041\n",
      "Accuracies on test: jigsaw : 0.000255, class : 0.435734\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 2/30 jigsaw : 3.484736, class : 0.835431 - acc jigsaw : 0.039062, class : 0.703125 [bs:128]\n",
      "10/42 of epoch 2/30 jigsaw : 3.528406, class : 1.015777 - acc jigsaw : 0.023438, class : 0.671875 [bs:128]\n",
      "20/42 of epoch 2/30 jigsaw : 3.494581, class : 0.847417 - acc jigsaw : 0.023438, class : 0.695312 [bs:128]\n",
      "30/42 of epoch 2/30 jigsaw : 3.551439, class : 0.900981 - acc jigsaw : 0.023438, class : 0.671875 [bs:128]\n",
      "40/42 of epoch 2/30 jigsaw : 3.504153, class : 0.775888 - acc jigsaw : 0.046875, class : 0.757812 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.014876, class : 0.826446\n",
      "Accuracies on test: jigsaw : 0.000255, class : 0.474930\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 3/30 jigsaw : 3.537663, class : 0.877541 - acc jigsaw : 0.007812, class : 0.703125 [bs:128]\n",
      "10/42 of epoch 3/30 jigsaw : 3.473274, class : 0.773478 - acc jigsaw : 0.039062, class : 0.710938 [bs:128]\n",
      "20/42 of epoch 3/30 jigsaw : 3.522653, class : 0.914493 - acc jigsaw : 0.007812, class : 0.656250 [bs:128]\n",
      "30/42 of epoch 3/30 jigsaw : 3.533078, class : 0.902381 - acc jigsaw : 0.007812, class : 0.664062 [bs:128]\n",
      "40/42 of epoch 3/30 jigsaw : 3.522029, class : 0.661984 - acc jigsaw : 0.031250, class : 0.750000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.013223, class : 0.828099\n",
      "Accuracies on test: jigsaw : 0.000764, class : 0.453296\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 4/30 jigsaw : 3.499679, class : 0.639075 - acc jigsaw : 0.039062, class : 0.765625 [bs:128]\n",
      "10/42 of epoch 4/30 jigsaw : 3.487955, class : 0.863903 - acc jigsaw : 0.039062, class : 0.695312 [bs:128]\n",
      "20/42 of epoch 4/30 jigsaw : 3.486789, class : 0.828046 - acc jigsaw : 0.007812, class : 0.718750 [bs:128]\n",
      "30/42 of epoch 4/30 jigsaw : 3.518275, class : 0.847476 - acc jigsaw : 0.023438, class : 0.695312 [bs:128]\n",
      "40/42 of epoch 4/30 jigsaw : 3.482301, class : 0.627639 - acc jigsaw : 0.039062, class : 0.796875 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.013223, class : 0.824793\n",
      "Accuracies on test: jigsaw : 0.000509, class : 0.428353\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 5/30 jigsaw : 3.477813, class : 0.672596 - acc jigsaw : 0.046875, class : 0.773438 [bs:128]\n",
      "10/42 of epoch 5/30 jigsaw : 3.460047, class : 0.757134 - acc jigsaw : 0.062500, class : 0.718750 [bs:128]\n",
      "20/42 of epoch 5/30 jigsaw : 3.498028, class : 0.673381 - acc jigsaw : 0.046875, class : 0.757812 [bs:128]\n",
      "30/42 of epoch 5/30 jigsaw : 3.458425, class : 0.713787 - acc jigsaw : 0.054688, class : 0.765625 [bs:128]\n",
      "40/42 of epoch 5/30 jigsaw : 3.498924, class : 0.772923 - acc jigsaw : 0.046875, class : 0.703125 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.013223, class : 0.824793\n",
      "Accuracies on test: jigsaw : 0.001018, class : 0.470349\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 6/30 jigsaw : 3.498768, class : 0.710146 - acc jigsaw : 0.007812, class : 0.734375 [bs:128]\n",
      "10/42 of epoch 6/30 jigsaw : 3.470558, class : 0.732223 - acc jigsaw : 0.054688, class : 0.757812 [bs:128]\n",
      "20/42 of epoch 6/30 jigsaw : 3.477911, class : 0.823226 - acc jigsaw : 0.039062, class : 0.671875 [bs:128]\n",
      "30/42 of epoch 6/30 jigsaw : 3.479684, class : 0.846705 - acc jigsaw : 0.070312, class : 0.679688 [bs:128]\n",
      "40/42 of epoch 6/30 jigsaw : 3.491648, class : 0.729533 - acc jigsaw : 0.007812, class : 0.750000 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.021488, class : 0.811570\n",
      "Accuracies on test: jigsaw : 0.001018, class : 0.442606\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 7/30 jigsaw : 3.482477, class : 0.769132 - acc jigsaw : 0.015625, class : 0.734375 [bs:128]\n",
      "10/42 of epoch 7/30 jigsaw : 3.489623, class : 0.831914 - acc jigsaw : 0.031250, class : 0.687500 [bs:128]\n",
      "20/42 of epoch 7/30 jigsaw : 3.471961, class : 0.718105 - acc jigsaw : 0.031250, class : 0.726562 [bs:128]\n",
      "30/42 of epoch 7/30 jigsaw : 3.529443, class : 0.683294 - acc jigsaw : 0.023438, class : 0.734375 [bs:128]\n",
      "40/42 of epoch 7/30 jigsaw : 3.480918, class : 0.831132 - acc jigsaw : 0.007812, class : 0.671875 [bs:128]\n",
      "Accuracies on val: jigsaw : 0.014876, class : 0.839669\n",
      "Accuracies on test: jigsaw : 0.000509, class : 0.439552\n",
      "New epoch - lr: 0.0, 0.001\n",
      "0/42 of epoch 8/30 jigsaw : 3.517887, class : 0.657668 - acc jigsaw : 0.023438, class : 0.773438 [bs:128]\n",
      "10/42 of epoch 8/30 jigsaw : 3.497504, class : 0.739406 - acc jigsaw : 0.046875, class : 0.710938 [bs:128]\n",
      "20/42 of epoch 8/30 jigsaw : 3.497984, class : 0.729836 - acc jigsaw : 0.007812, class : 0.773438 [bs:128]\n",
      "30/42 of epoch 8/30 jigsaw : 3.466294, class : 0.727095 - acc jigsaw : 0.046875, class : 0.718750 [bs:128]\n"
     ]
    }
   ],
   "source": [
    "from train_jigsaw import Trainer\n",
    "\n",
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (\"-\".join(args.source),\n",
    "                                                            args.target,args.epochs, args.jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\"train\": data_helper.get_dataloader(args.source, args.jigsaw_n_classes, \"train\"),\n",
    "           \"val\": data_helper.get_dataloader(args.target, args.jigsaw_n_classes, \"val\")}\n",
    "dataset_sizes = {\"train\": len(dataloaders[\"train\"].dataset),\n",
    "                \"val\": len(dataloaders[\"val\"].dataset)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim_and_scheduler(network, epochs, lr):\n",
    "    from torch import optim\n",
    "    optimizer = optim.SGD(network.get_params(lr), weight_decay=.0005, momentum=.9, nesterov=True, lr=lr)\n",
    "    step_size = int(epochs * .8)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size)\n",
    "    print(step_size)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "model_ft = model_factory.get_network(\"caffenet\")(jigsaw_classes=args.jigsaw_n_classes+1, classes=args.n_classes)\n",
    "model_ft = model_ft.to(device)\n",
    "# print(model_ft)\n",
    "\n",
    "optimizer, scheduler = get_optim_and_scheduler(model_ft, args.epochs, args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, source, target, optimizer, logger, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for it, ((data, jig_l, class_l), d_idx) in enumerate(source):\n",
    "        data, jig_l, class_l = data.to(device), jig_l.to(device), class_l.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        jigsaw_logit, class_logit = model(data)\n",
    "        jigsaw_loss = criterion(jigsaw_logit, jig_l)\n",
    "        class_loss = criterion(class_logit[d_idx!=target_id], class_l[d_idx!=target_id])\n",
    "        _, cls_pred = class_logit.max(dim=1)\n",
    "        _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "        loss = class_loss + jigsaw_loss * jig_weight\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logger.log(it, len(source), {\"jigsaw\": jigsaw_loss.item(), \"class\": class_loss.item()},\n",
    "                  {\"jigsaw\": torch.sum(jig_pred == jig_l.data).item(), \"class\":torch.sum(cls_pred == class_l.data).item()},\n",
    "                  data.shape[0])\n",
    "        del loss, class_loss, jigsaw_loss, jigsaw_logit, class_logit\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        jigsaw_correct = 0\n",
    "        class_correct = 0\n",
    "        total = 0\n",
    "        for it, ((data, jig_l, class_l), d_idx) in enumerate(target):\n",
    "            data, jig_l, class_l = data.to(device), jig_l.to(device), class_l.to(device)\n",
    "            jigsaw_logit, class_logit = model(data)\n",
    "            _, cls_pred = class_logit.max(dim=1)\n",
    "            _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "            class_correct += torch.sum(cls_pred == class_l.data)\n",
    "            jigsaw_correct += torch.sum(jig_pred == jig_l.data)\n",
    "            total += data.shape[0]\n",
    "        logger.log_test({\"jigsaw\": float(jigsaw_correct) / total,\n",
    "                         \"class\": float(class_correct) / total})\n",
    "\n",
    "\n",
    "def do_training(args, model, source, target, optimizer, scheduler, device):\n",
    "    logger = Logger(args)\n",
    "    for k in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        logger.new_epoch(scheduler.get_lr())\n",
    "        do_epoch(model, source, target, optimizer, logger, device)\n",
    "    return logger, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jig_weight = args.jig_weight\n",
    "logger, model = do_training(args, model_ft, dataloaders[\"train\"], dataloaders[\"val\"], optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (str(args.source),args.target,args.epochs, jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    import numpy as np\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "conv1 = model_ft.features[0] # models.alexnet(pretrained=True).features[0] #model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (str(source),target,epochs, jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,k in enumerate(range(0,l,int(updates))):\n",
    "    print(k, logger.val_acc[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# iter_c = iter(train_datasets)\n",
    "\n",
    "# for x in range(5):\n",
    "#     tmp = next(iter_c)\n",
    "#     image = to_plt(tmp[0])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os.path import join, dirname\n",
    "# from data.JigsawLoader import JigsawTestDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)\n",
    "# test = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "iter_c = iter(data_helper.get_dataloader(\"photo\", 31, \"train\"))\n",
    "(tmp, v, c), d = next(iter_c)\n",
    "for x in range(5):\n",
    "    image = tmp[x]\n",
    "    image = torchvision.utils.make_grid(tmp[x],1,normalize=True)\n",
    "    plt.imshow(to_plt(image))\n",
    "    plt.show()\n",
    "    print(v[x],c[x])\n",
    "    \n",
    "print(v.max(), v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d[d==k].shape for k in [0,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.JigsawLoader import JigsawDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._augment_tile = transforms.Compose([\n",
    "#             transforms.RandomCrop(64),\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        data = torch.stack(tiles, 0)\n",
    "        return self.returnFunc(data), 0, int(self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
